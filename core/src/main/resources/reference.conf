

###################
# Task subsystem  #
###################

# This subsystem allows jobs to be executed over a set of
# computers.
# It tracks which job is finished and remembers
# the result across runs. (this is termed "cache" in later on)
# It has a simple file sharing facility in case a shared filesystem is not
# available.
# It has very simple resource definitions (CPU,RAM).
# It supports automatic "elastic" shrinking and growing of the
#  available nodes via SSH or Amazon AWS.
# It works without these systems if you manually start the workers.
#

hosts.port = 28888

# number of available CPU's on the current machine
hosts.numCPU = 1

# number of available ram on the current machine in Mb
hosts.RAM = 96000

# number of CPU's reserved for purposes other than Tasks
hosts.reservedCPU = 0

# hostname of the current machine.
hosts.hostname = "localhost"

#LSF or SGE or EC2 or SSH
tasks.elastic.engine = "NOENGINE"

# advanced. may specify an ip:port where a cacherActor is listening
hosts.remoteCacheAddress = none

# !Important!
# This file has the progress tracking across runs.
# If deleted, most of the progress is lost.
tasks.cache.file = "cache.leveldb"

# leave empty to disable file log
tasks.logFile = ""

# writes akka log to stdout
tasks.stdout = true

# Keep track of the progress or not?
tasks.cache.enabled = true

tasks.cache.store = "filesystem"

tasks.proxytaskGetBackResultTimeout = 28 days

# !Important!
# This is the folder where valuable result and itermediare files
# are written
tasks.fileservice.storageURI = "./"

tasks.fileservice.threadPoolSize = 8

# Cache checks whether a file is still accessible. If not treats it as no hit.
tasks.verifySharedFileInCache = true

# !Important!
# Every input file except those which are found in the below listed folders
# are copied to the tasks.fileServiceBaseFolder .
tasks.fileservice.extendedFolders = []

# Individuals compute nodes can access the tasks.fileServiceBaseFolder .
# If not then the file copy operations are
# routed trough the master node.
tasks.fileservice.baseFolderIsShared = false

tasks.nonLocalFileSystems = []

# !Important!
# The file sharing facility works by assigning a unique name to every file.
# If 2 input files whould have the same basename (filename without path) then
# those 2 would clash. This setting will cause to have the full path in the
# unique names of the input files.
tasks.includeFullPathInDefaultSharedName = false

# !Important!
# Resubmit failed tasks for execution.
# Leads to infinite loop if failure is systematic.
tasks.resubmitFailedTask = false

# Ping interval between worker and queue.
tasks.askInterval = 100 ms

tasks.disableRemoting = false

tasks.skipContentHashVerificationAfterCache = false

# !Important!
# The automatic "elastic" shrinking growing system is enabled.
tasks.elastic.runscript = """tar xf {PACKAGE} && bin/entrypoint -J-Xmx{RAM}M -Dtasks.elastic.engine={GRID} {EXTRA} -Dhosts.master={MASTER}"""

tasks.elastic.bin = ""

# Kill a node if it is idle after x time.
tasks.elastic.idleNodeTimeout = 900 s

# Max nodes to spawn at a given instant
tasks.elastic.maxNodes = 1

# Max nodes to spawn, cumulative from start of application
tasks.elastic.maxNodesCumulative = 10

# Max pending nodes. After this is reached no new node request is submitted.
tasks.elastic.maxPending = ${tasks.elastic.maxNodes}

# The elastic subsystem checks the task queue this often.
tasks.elastic.queueCheckInterval = 60 s

tasks.elastic.queueCheckInitialDelay = 5 s

tasks.elastic.nodeKillerMonitorInterval = 5 s

tasks.elastic.email = ""

tasks.elastic.logQueueStatus = true

# The jvmMaxHeapFactor * requestedMemOfNewNode is assigned to -Xmx
tasks.elastic.jvmMaxHeapFactor = 0.7

# This is an object in which every child object represents a node.
# The child objects have the following fields:
# hostname keyFile username memory cpu extraArgs
# keyFile points to unencrypted passphrase-less openssh keyfile.
tasks.elastic.ssh.hosts = {}

tasks.fileSendChunkSize = 16 MiB

tasks.elastic.javaCommandline = ""

# Settings for the Amazon AWS interface.
# These are mostly in line with the LSF settings adapted to AWS.
tasks.elastic.aws {

      terminateMaster = false

      fileStoreBucket = ""

      fileStoreBucketFolderPrefix = ""

      useS3FileStore = true

      endpoint = "http://ec2.us-east-1.amazonaws.com"

      spotPrice = 0.271

      # instance store 64 bit: ami-570f603e
      # for cluster compute nodes: ami-a73758ce
      ami = "ami-a73758ce"

      instanceType = "cc2.8xlarge"

      securityGroup = ""

      extraFilesFromS3 = []

      extraStartupScript = ""

      jvmMaxHeapFactor = 0.5

      keyName = ""

      iamRole = ""

      placementGroup = ""

}

# Akka DeadlineFailureDetector
tasks.failuredetector {

	heartbeat-interval = 1000 ms

      # if heatbeats pause for this duration, the detector will pull alarm
      acceptable-heartbeat-pause = 600 s
}

######################
# Task subsystem end #
######################
